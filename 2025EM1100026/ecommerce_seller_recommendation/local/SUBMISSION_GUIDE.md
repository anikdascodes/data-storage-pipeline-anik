# E-commerce Recommendation System - Submission Guide

**Student:** MSc Data Science & AI  
**Roll No:** 2025EM1100026  
**Assignment:** Data Storage and Pipeline  

---

## ğŸ¯ Quick Start for Teacher Evaluation

### Option 1: One-Click Execution (Recommended)

```bash
bash RUN_ASSIGNMENT.sh
```

This interactive script provides three execution modes:
1. **Docker** (no setup required)
2. **Local** (requires Spark)
3. **Complete Demo** (both clean and dirty data)

### Option 2: Docker Execution

```bash
docker compose up --build
```

### Option 3: Complete Demo (Showcases DQ Framework)

```bash
bash run_complete_demo.sh
```

---

## ğŸ“Š What This Assignment Demonstrates

### âœ… All Assignment Requirements Met

1. **3 ETL Pipelines** - Seller Catalog, Company Sales, Competitor Sales
2. **1 Consumption Layer** - Recommendation Generation
3. **Apache Hudi Integration** - Schema evolution, incremental upserts
4. **Medallion Architecture** - Bronze â†’ Silver â†’ Gold layers
5. **Quarantine Zone** - Invalid records isolation with failure reasons
6. **Data Quality Framework** - Comprehensive validation rules
7. **YAML Configuration** - Flexible path management
8. **Docker Containerization** - Zero-setup execution

### ğŸ” Enhanced Features

1. **Dual Dataset Processing:**
   - **Clean Data:** Production-ready processing
   - **Dirty Data:** DQ framework demonstration

2. **Comprehensive Validation:**
   - Missing value checks
   - Data type validation
   - Business rule enforcement
   - Date format validation

3. **Production-Ready Architecture:**
   - Error handling and logging
   - Configurable paths
   - Scalable design patterns

---

## ğŸ“ Project Structure

```
2025EM1100026/ecommerce_seller_recommendation/local/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ ecomm_local.yml      # Clean data configuration
â”‚   â”œâ”€â”€ ecomm_dirty.yml      # Dirty data configuration
â”‚   â””â”€â”€ ecomm_prod.yml       # Production configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl_seller_catalog.py
â”‚   â”œâ”€â”€ etl_company_sales.py
â”‚   â”œâ”€â”€ etl_competitor_sales.py
â”‚   â””â”€â”€ consumption_recommendation.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ etl_seller_catalog_spark_submit.sh
â”‚   â”œâ”€â”€ etl_company_sales_spark_submit.sh
â”‚   â”œâ”€â”€ etl_competitor_sales_spark_submit.sh
â”‚   â””â”€â”€ consumption_recommendation_spark_submit.sh
â”œâ”€â”€ raw/                     # Input datasets (clean and dirty)
â”œâ”€â”€ processed/               # Output Hudi tables and CSV
â”œâ”€â”€ quarantine/              # Invalid records with failure reasons
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ RUN_ASSIGNMENT.sh        # Quick start script
â”œâ”€â”€ run_complete_demo.sh     # Complete demo script
â””â”€â”€ README.md                # Detailed documentation
```

---

## ğŸš€ Expected Outputs

### Successful Execution Produces:

1. **Hudi Tables:**
   - `processed/seller_catalog_hudi/`
   - `processed/company_sales_hudi/`
   - `processed/competitor_sales_hudi/`

2. **Final Recommendations:**
   - `processed/recommendations_csv/seller_recommend_data.csv`

3. **Quarantine Records (if dirty data):**
   - `quarantine/seller_catalog/`
   - `quarantine/company_sales/`
   - `quarantine/competitor_sales/`

### Sample Results:
- **Clean Data:** ~2,000 recommendations generated
- **Dirty Data:** ~1,800 recommendations + quarantined invalid records

---

## ğŸ”§ Technical Specifications

- **Spark Version:** 3.5.0
- **Hudi Version:** 0.15.0
- **Java Version:** 21
- **Python Version:** 3.10+
- **Docker:** Ubuntu 22.04 base image

---

## ğŸ“‹ Evaluation Checklist

- [x] **ETL Ingestion (15 marks)** - 3 pipelines with Hudi integration
- [x] **Consumption Layer (5 marks)** - Recommendation generation
- [x] **Data Cleaning & DQ** - Comprehensive validation framework
- [x] **Quarantine Zone** - Invalid records handling
- [x] **Schema Evolution** - Hudi table management
- [x] **YAML Configuration** - Flexible path management
- [x] **Docker Containerization** - Zero-setup execution
- [x] **Production Architecture** - Medallion pattern implementation

---

## ğŸ‰ Assignment Highlights

1. **Complete Implementation:** All requirements fully implemented
2. **Enhanced DQ Framework:** Demonstrates both clean and dirty data processing
3. **Production-Ready:** Docker containerization for easy deployment
4. **Comprehensive Documentation:** Detailed README and inline comments
5. **Easy Evaluation:** One-click execution scripts for teachers

---

**Ready for submission and evaluation!** ğŸš€